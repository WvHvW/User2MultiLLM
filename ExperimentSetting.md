# 研究背景
1. 允许用户被不同LLM服务，即来自同一用户节点的流量在分流算法下，可以路由到多个LLM被服务
2. LLM作为服务节点，不能出现在路径中间，只能作为路径终点。在加载LLM信息时，就要去掉LLM的出边，只允许其他节点接入LLM，不允许再有流量从LLM流出（但是允许从LLM流向超级汇点）

# 网络设置
## 中等规模网络
1. 节点数目[20, 40, 60, 80]
2. 每个节点度数范围在[3, 4, 5]
3. 网络包含8个user节点和4个LLM节点
4. LLM的服务容量表示其在单位时间内可服务的最大输入流量，范围在[100, 150, 200]Gbps
5. 每个用户节点产生的流量需求范围在[30, 40, 50]Gbps
6. 每条链路的带宽范围为[100, 200, 300, 400]Gbps，其cost和距离相关，归一化到[1, 10]以内
7. user和LLM节点分布均遵循['uniform', 'sparse', 'poisson', 'gaussian']这四种分布

## 大规模网络
1. 节点数目[100, 200, 300, 400]
2. 每个节点度数范围在[5, 6, 7]
3. 网络包含48个user节点和12个LLM节点
4. LLM的服务容量表示其在单位时间内可服务的最大输入流量，范围在[200, 250, 300]Gbps
5. 每个用户节点产生的流量需求范围在[30, 40, 50]Gbps
6. 每条链路的带宽范围为[100, 200, 300, 400]Gbps，其cost和距离相关，归一化到[1, 10]以内
7. user和LLM节点分布均遵循['uniform', 'sparse', 'poisson', 'gaussian']这四种分布

# 性能指标
1. 路由总花销（Total Cost）表明该路由算法产生的总链路开销。
2. 服务接收率（Acceptance Ratio）是被服务的流量与所有用户产生的流量需求的比值。
3. 运行时间（Runtime）用于衡量该路由算法在不同方案下的运行时间效率。

# 对比算法
1. no-split
   1. 从一个用户节点流出的流量不允许被分流，只能作为一个整体被路由到LLM
   2. 用户分配顺序按流量需求降序排序
2. no-split（带汇集图）
   1. 所有LLM连接到超汇T
   2. 依次路由各个user到T，选择开销最小的作为本轮分配结果
3. 1-split
   1. 首先生成汇集图：将所有用户连接到超级源点S，S->user的链路的属性满足以下要求
      1. S->user的边是单向物理边，生成残量网络时没有反向边
      2. 链路带宽为user.bw
      3. cost为极小值。
   2. 再将所有llm连接到超级汇点T，llm->T的链路属性满足以下要求
      1. llm->T的边是单向物理边，生成残量网络时没有反向边
      2. 链路带宽为llm服务容量
      3. cost为极小值
   3. 每一轮的推流粒度为1
4. 1-split（不带汇集图）
   1. 将user流量分流到user_ideal_llm前几个llm
   2. 用户分配顺序按流量需求降序排列
5. bottleneck-split
   1. 首先生成汇集图：将所有用户连接到超级源点S，S->user的链路的属性满足以下要求
      1. S->user的边是单向物理边，生成残量网络时没有反向边
      2. 链路带宽为user.bw
      3. cost为极小值。
   2. 再将所有llm连接到超级汇点T，llm->T的链路属性满足以下要求
      1. llm->T的边是单向物理边，生成残量网络时没有反向边
      2. 链路带宽为llm服务容量
      3. cost为极小值
   3. 使用链路瓶颈流量作为每一轮的推流粒度
6. bottleneck-split（不带汇集图）
   1. 将user流量分流到user_ideal_llm前几个llm
   2. 用户分配顺序按流量需求降序排列
7. LLM-split
   1. 是一个分流算法，分流粒度为user_ideal_llm里最靠前的llm剩余容量，直至这个用户流量被完全服务。例如user1总流量需求有5个单位，其理想llm序列中，第一个llm还有3单位容量，那么本轮从user1节点推送3单位流量给它；第二个llm没有容量了，跳过它；第三个llm还有5单位容量，将user剩余的2两单位推送给它。
   2. 用户分配顺序按默认索引顺序即可
8. LLM-split（带汇集图）
   1. 所有用户连接到超源S，所有LLM连接到超汇T
   2. S -> user的权重为user到各自user_ideal_llm中最近一个可用llm的距离，为了不影响总成本，这个权重要映射到极小值范围内，但是能用来选择用户
   3. 推流粒度为用户剩余流量需求和llm剩余容量间的较小值
9. 1-split-augment
   1. 首先生成汇集图：将所有用户连接到超级源点S，S->user的链路的属性满足以下要求
      1. S->user的边是单向物理边，生成残量网络时没有反向边
      2. 链路带宽为user.bw
      3. cost为极小值。
   2. 再将所有llm连接到超级汇点T，llm->T的链路属性满足以下要求
      1. llm->T的边是单向物理边，生成残量网络时没有反向边
      2. 链路带宽为llm服务容量
      3. cost为极小值
   3. 每一轮的推流粒度为1
   4. 记得要消除负环
10. bottleneck-split-augment
   1. 首先生成汇集图：将所有用户连接到超级源点S，S->user的链路的属性满足以下要求
      1. S->user的边是单向物理边，生成残量网络时没有反向边
      2. 链路带宽为user.bw
      3. cost为极小值。
   2. 再将所有llm连接到超级汇点T，llm->T的链路属性满足以下要求
      1. llm->T的边是单向物理边，生成残量网络时没有反向边
      2. 链路带宽为llm服务容量
      3. cost为极小值
   3. 使用链路瓶颈流量作为每一轮的推流粒度
   4. 记得要消除负环

# 实验主流程
1. 依次从sheets里读取网络信息，不同规模网络保存在“N-xxx”目录下，如20节点网络信息就在“N-20”文件夹里
2. 每个网络设置下得到的结果保存在results/N-xxx目录下
3. 大循环是两层，第一层是全网络带宽设为[100, 200, 300, 400]Gbps，第二层是所有LLM服务容量设为[100, 150, 200]Gbps。即要研究统一带宽时LLM服务容量变化带来的影响和统一LLM服务容量时带宽变化带来的影响
4. 网络设置下又是两层循环，第一层是user分布，第二层是llm分布
5. 每一套网络设置下，依次调用对比算法，记录字段包括：运行时间、总开销、优化率、服务率、前20条关键链路（根据介数中心性排列）的平均利用率，llm到user的平均距离（所有llm到所有user的距离加和后用sigmoid归一化）
6. 记录的文件包括
   1. “N-xxx-results.xlsx”，第一列是带宽设置，第二列是LLM服务容量设置，第三列是user分布，第四列是llm分布，第五列是算法名，往后是各个记录字段。这个文件保存在results/N-xxx目录下
   2. “N-size-results.xlsx”，sheet名为对应的user_distribution-llm_distribution，第一列是带宽设置，第二列是LLM服务容量设置，第三列是网络节点个数，第四列是算法名，第五列是运行时间，第六列是总花销，第七列是服务率。这个文件保存在results目录下即可
   3. 记录1-split、1-split-no-aggregate和1-split-augment的结果，名为“withdraw-optimization.xlsx”，sheet名为对应的user_distribution-llm_distribution，第一列是带宽设置，第二列是LLM服务容量设置，第三列是1-split-no-aggregate算法名，第四列是1-split算法名，第五列是1-split-augment算法名，第六列是迭代次数，第七列是1-split-no-aggregate截至当前轮次总花销，第八列是1-split截至当前轮次总花销，第九列是1-split-augment截至当前轮次总花销。这个文件保存在results/N-xxx目录下